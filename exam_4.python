import tensorflow as tf
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt

# MNIST 데이터셋 로드 (손글씨 데이터)
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# 데이터 전처리: 0-255 범위의 픽셀 값을 0-1 범위로 정규화
# x_train, x_test 는 MNIST 의 이미지 데이터 (픽셀 값 0~255)
# 각 픽셀 값을 255.0으로 나누면, 0~1 사이의 값으로 변환
# 이 과정을 정규화라고 함
x_train, x_test = x_train / 255.0, x_test / 255.0
print(x_train.min(), x_train.max())  
# 출력 예시: 0.0 1.0
# 픽셀 값이 0.0(검은색) ~ 1.0(흰색) 사이의 실수(float) 값
# 값의 범위를 일정하게 맞추면, 가중치 업데이트가 균형 있게 진행됨
# 즉, 픽셀 값을 0~1 사이로 정규화해서 학습이 더 잘 되도록 만듦

# 모델 입력 형식에 맞게 데이터 차원 변경 (28x28 이미지를 28x28x1 형태로 변경)
# CNN 모델이 이미지 학습을 하려면 4차원(배치크기, 높이, 너비, 채널) 형태로 변환해야 함
# 1차원-펼친 벡터 - (784,)
# 2차원-흑백 이미지 - (28,28)
# 3차원-CNN 에서 사용하는 이미지 형태 - (28,28,1)
# 4차원-CNN 모델의 입력 형태 - (60000, 28,28,1) 
# 4차원은 채널 정보(색상) 을 포함한 데이터 형태를 원함. 
# 그래서, (28, 28) 를 채널 차원(1) 을 추가 그리고, -1은 샘플 개수 (60000, 10000) 를 자동으로 맞춰주는 역할 
# 흑백 이미지는 채널이 1(28,28,1), 컬러(RGB) 이미지는 (28, 28, 3)
x_train = x_train.reshape((-1, 28, 28, 1))
x_test = x_test.reshape((-1, 28, 28, 1))


#모델 정의
# 모델 생성 : Sequential -> 순차적인 신경망 모델 , 신경망의 층(Layer)들을 차례로 쌓아가는 방식 
model = models.Sequential([
    # 32 -> 이 층에서 사용하는 필터(커널) 개수 (32개의 특징 맵 생성), (3,3) -> 3x3 크기의 필터를 사용, activation='relu' -> ReLU(Rectified Linear Unit) 활성화 함수 사용, 입력 데이터 크기 (높이 28, 너비 28, 채널 1) 채널1은 mnist 는 흑백 이미지
    # 중요한 특징(엣지, 모양 등)을 추출하는 역할
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    # 첫 번째 풀링층(MaxPooling2D) -> 2x2 크기의 최대 풀링(Max Pooling) -> 가장 큰 값만 남기고 나머지는 버림 (28 * 28 -> 14 * 14)
    layers.MaxPooling2D((2, 2)),
    # 필터 개수를 64개로 늘림 -> 더 복잡한 패턴을 학습할 수 있도록 함 -> 더 깊은 특징 (패턴, 윤곽 등 )을 학습 ** 64개의 필터 (필터는 이미지에서 특징 추출을 하고 작은 행렬단위형태임)
    layers.Conv2D(64, (3, 3), activation='relu'),
    # 14 * 14 -> 7 * 7
    layers.MaxPooling2D((2, 2)),
    # 필터 개수를 그대로 64개 유지 , 풀링을 하지 않고, 더 깊은 특징을 추출 
    layers.Conv2D(64, (3, 3), activation='relu'),
    # 2D  -> 1D 로 변환 
    # cnn 층을 지나면 데이터가 (7,7,64) 형태의 3D 텐서가 됨, flatten()을 사용하면 1D 벡터로 변환 (배치 크기, 7, 7, 64)  # 예제: 7x7 크기의 특징 맵 64개 ==> (배치 크기, 7 * 7 * 64)  # 즉, (배치 크기, 3136) 이렇게로 그래서 3136 으로 1차원이 됨
    layers.Flatten(),
    # Dense(64) -> 64개의 뉴런을 가진 완전 연결층(FC Layer), ReLU 활성화 함수 사용 ** 64개의 뉴런(뉴런은 가중치 계산을 하기 위함.즉 입력값(이미지 특징 , 이전 층의 출력) 을 받아 가중치를 더한 후 활성화 함수(ReLU, Sigmoid)를 통과시켜 결과를 출력하여 다른 층으로 전달)
    layers.Dense(64, activation='relu'),
    # Dense(10) -> 출력 뉴런 10개 (0~9  숫자 분류)
    layers.Dense(10, activation='softmax')  # 10개의 클래스 (0-9)
])

# 모델 컴파일
# 가중치 업데이트(Adam 옵티마이저 사용), Sparse categorical crossentropy 손실 함수 사용하여 다중 클래스 분류 문제 예측 오차를 계산, 정확도 평가 지표 
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',  # 다중 분류를 위한 손실 함수
              metrics=['accuracy'])

# 모델 학습
# 훈련 데이터를 사용하여 모델을 훈련하고, 주어진 에포크(epoch) 수 만큼 반복 
model.fit(x_train, y_train, epochs=5)

# 테스트 데이터로 모델 평가 (입력 이비미지들, 정답 레이블, 출력의 상세정도)
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)
print(f"Test accuracy: {test_acc}")


# 예측을 위한 샘플 이미지 출력
plt.imshow(x_test[0].reshape(28, 28), cmap='gray')
plt.show()

# 예측 결과 확인
predictions = model.predict(x_test)
print(f"Predicted label: {predictions[0].argmax()}")  # 가장 높은 확률을 가진 클래스
